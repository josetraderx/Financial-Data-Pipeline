{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79157571",
   "metadata": {},
   "source": [
    "# Exodus v2025 Financial Data Pipeline: End-to-End ETL Demo\n",
    "\n",
    "Este notebook demuestra el flujo principal del pipeline de datos financieros Exodus v2025, incluyendo extracci√≥n, validaci√≥n, almacenamiento, splits y monitoreo. Ideal para mostrar en LinkedIn o exportar como PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8237d021",
   "metadata": {},
   "source": [
    "## Tabla de Contenidos\n",
    "1. Importar librer√≠as\n",
    "2. Cargar configuraci√≥n\n",
    "3. Inicializar pipeline\n",
    "4. Descarga y procesamiento b√°sico\n",
    "5. Pipeline avanzado con base de datos\n",
    "6. Validaci√≥n de datos\n",
    "7. Almacenamiento en TimescaleDB\n",
    "8. Almacenamiento de metadatos\n",
    "9. Splits de datos\n",
    "10. M√©tricas de calidad\n",
    "11. Monitoreo y logging\n",
    "12. Pruebas unitarias e integraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6965c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importar librer√≠as necesarias\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from src.data_etl.pipelines.crypto_pipeline import CryptoPipeline\n",
    "from src.data_etl.pipelines.config_manager import PipelineConfig\n",
    "from src.data_etl.processing.enhanced_metadata_manager import EnhancedMetadataManager\n",
    "from src.data_etl.processing.data_cleaner import DataCleaner\n",
    "from src.data_etl.processing.data_splitter import DataSplitter\n",
    "from src.data_etl.validation.data_validator import EnhancedDataValidator\n",
    "from src.data_etl.storage.timeseries_db import TimeSeriesDB\n",
    "from src.data_etl.storage.metadata_db import MetadataDB\n",
    "\n",
    "# Librer√≠as para visualizaci√≥n moderna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "\n",
    "# Configurar estilo moderno\n",
    "plt.style.use('dark_background')\n",
    "sns.set_palette(\"husl\")\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f815430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Cargar configuraci√≥n del pipeline\n",
    "config_path = 'config/pipeline_config.json'\n",
    "with open(config_path, 'r') as f:\n",
    "    config_json = json.load(f)\n",
    "config = PipelineConfig(config_path)\n",
    "print('Configuraci√≥n cargada:')\n",
    "print(json.dumps(config_json, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e37e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Inicializar el CryptoPipeline\n",
    "pipeline = CryptoPipeline(config.get())\n",
    "print('Pipeline inicializado.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9883e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Descarga y procesamiento b√°sico de datos\n",
    "pipeline_config = config.create_pipeline_config(\n",
    "    provider='bybit',\n",
    "    symbol='BTCUSDT',\n",
    "    timeframe='1h',\n",
    "    days_back=30,\n",
    "    save_files=True,\n",
    "    store_db=False\n",
    ")\n",
    "results = pipeline.run_pipeline(pipeline_config)\n",
    "print('Descarga y procesamiento b√°sico completados.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68357eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Pipeline avanzado con almacenamiento en base de datos\n",
    "advanced_config = config.create_pipeline_config(\n",
    "    provider='bybit',\n",
    "    symbol='ETHUSDT',\n",
    "    timeframe='4h',\n",
    "    days_back=30,\n",
    "    splits={\n",
    "        'train_test_split': {\n",
    "            'test_size': 0.2,\n",
    "            'method': 'chronological'\n",
    "        }\n",
    "    },\n",
    "    store_db=True,\n",
    "    save_files=True\n",
    ")\n",
    "advanced_results = pipeline.run_pipeline(advanced_config)\n",
    "print('Pipeline avanzado ejecutado.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98631b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Validaci√≥n de los datos descargados\n",
    "validator = EnhancedDataValidator()\n",
    "data = results['data'] if 'data' in results else None\n",
    "if data is not None:\n",
    "    report = validator.validate(data)\n",
    "    print('Reporte de validaci√≥n:')\n",
    "    print(json.dumps(report, indent=2))\n",
    "else:\n",
    "    print('No se encontraron datos para validar.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab0f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualizaci√≥n Moderna de Datos OHLCV\n",
    "if data is not None and len(data) > 0:\n",
    "    # Crear gr√°fico de velas moderno con Plotly\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Agregar candlestick chart\n",
    "    fig.add_trace(go.Candlestick(\n",
    "        x=data.index,\n",
    "        open=data['open'],\n",
    "        high=data['high'],\n",
    "        low=data['low'],\n",
    "        close=data['close'],\n",
    "        name='BTCUSDT',\n",
    "        increasing_line_color='#00ff88',\n",
    "        decreasing_line_color='#ff0044'\n",
    "    ))\n",
    "    \n",
    "    # Agregar volumen en subplot\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=data.index,\n",
    "        y=data['volume'],\n",
    "        name='Volumen',\n",
    "        yaxis='y2',\n",
    "        opacity=0.3,\n",
    "        marker_color='#ffd700'\n",
    "    ))\n",
    "    \n",
    "    # Configurar layout moderno\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': 'üìà BTCUSDT - An√°lisis T√©cnico Avanzado',\n",
    "            'x': 0.5,\n",
    "            'font': {'size': 20, 'color': '#ffffff'}\n",
    "        },\n",
    "        xaxis_title='Fecha',\n",
    "        yaxis_title='Precio (USDT)',\n",
    "        yaxis2=dict(title='Volumen', overlaying='y', side='right'),\n",
    "        template='plotly_dark',\n",
    "        height=600,\n",
    "        showlegend=True,\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Dashboard de m√©tricas r√°pidas\n",
    "    metrics_data = {\n",
    "        'M√©trica': ['Precio Actual', 'M√°ximo 30d', 'M√≠nimo 30d', 'Volatilidad', 'Volumen Promedio'],\n",
    "        'Valor': [\n",
    "            f\"${data['close'].iloc[-1]:,.2f}\",\n",
    "            f\"${data['high'].max():,.2f}\",\n",
    "            f\"${data['low'].min():,.2f}\",\n",
    "            f\"{data['close'].pct_change().std() * 100:.2f}%\",\n",
    "            f\"{data['volume'].mean():,.0f}\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    print(\"\\n‚ö° M√©tricas R√°pidas:\")\n",
    "    print(metrics_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No hay datos disponibles para visualizar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e3c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Almacenamiento en TimescaleDB\n",
    "db_config = config_json['db_config']\n",
    "timescale_db = TimeSeriesDB(db_config)\n",
    "timescale_db.connect()\n",
    "timescale_db.create_hypertable()\n",
    "if data is not None:\n",
    "    timescale_db.insert_data(data)\n",
    "    print('Datos almacenados en TimescaleDB.')\n",
    "else:\n",
    "    print('No hay datos para almacenar en TimescaleDB.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e033871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Almacenamiento de metadatos y reporte de validaci√≥n\n",
    "metadata_db = MetadataDB(db_config)\n",
    "metadata_db.connect()\n",
    "metadata_db.create_tables()\n",
    "if data is not None and 'report' in locals():\n",
    "    dataset_id = metadata_db.insert_dataset_metadata({'symbol': 'BTCUSDT', 'timeframe': '1h'})\n",
    "    metadata_db.insert_validation_report(dataset_id, report)\n",
    "    print('Metadatos y reporte de validaci√≥n almacenados.')\n",
    "else:\n",
    "    print('No hay metadatos o reporte para almacenar.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5e5b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Splits de datos\n",
    "splitter = DataSplitter()\n",
    "if data is not None:\n",
    "    # Split cronol√≥gico\n",
    "    train, test = splitter.train_test_split(data, test_size=0.2, method='chronological')\n",
    "    print(f'Split cronol√≥gico: train={len(train)}, test={len(test)}')\n",
    "    # Split por fecha\n",
    "    from datetime import datetime\n",
    "    splits = splitter.split_by_date(data, split_date=datetime(2024, 1, 1))\n",
    "    print(f'Split por fecha: {[(k, len(v)) for k,v in splits.items()]}')\n",
    "    # Sliding window\n",
    "    windows = splitter.create_sliding_windows(data, window_size=100, step_size=10)\n",
    "    print(f'Sliding windows generados: {len(windows)}')\n",
    "else:\n",
    "    print('No hay datos para realizar splits.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d5ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî™ Visualizaci√≥n de Splits de Datos\n",
    "if data is not None and 'train' in locals() and 'test' in locals():\n",
    "    # Crear visualizaci√≥n de splits cronol√≥gicos\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Datos de entrenamiento\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=train.index,\n",
    "        y=train['close'],\n",
    "        mode='lines',\n",
    "        name='Training Set',\n",
    "        line=dict(color='#00ff88', width=2),\n",
    "        hovertemplate='<b>Training</b><br>Fecha: %{x}<br>Precio: $%{y:.2f}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    # Datos de prueba\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=test.index,\n",
    "        y=test['close'],\n",
    "        mode='lines',\n",
    "        name='Test Set',\n",
    "        line=dict(color='#ff6b35', width=2),\n",
    "        hovertemplate='<b>Test</b><br>Fecha: %{x}<br>Precio: $%{y:.2f}<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    # L√≠nea divisoria\n",
    "    split_date = test.index[0]\n",
    "    fig.add_vline(\n",
    "        x=split_date,\n",
    "        line=dict(color='white', dash='dash', width=2),\n",
    "        annotation_text='Split Point',\n",
    "        annotation_position='top'\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': 'üìà Visualizaci√≥n de Train/Test Split - Datos Cronol√≥gicos',\n",
    "            'x': 0.5,\n",
    "            'font': {'size': 16, 'color': '#ffffff'}\n",
    "        },\n",
    "        xaxis_title='Fecha',\n",
    "        yaxis_title='Precio de Cierre (USDT)',\n",
    "        template='plotly_dark',\n",
    "        height=500,\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    # Estad√≠sticas de los splits\n",
    "    split_stats = pd.DataFrame({\n",
    "        'Dataset': ['Training', 'Test', 'Total'],\n",
    "        'Registros': [len(train), len(test), len(data)],\n",
    "        'Porcentaje': [f\"{len(train)/len(data)*100:.1f}%\", f\"{len(test)/len(data)*100:.1f}%\", \"100.0%\"],\n",
    "        'Fecha Inicio': [train.index[0].strftime('%Y-%m-%d'), test.index[0].strftime('%Y-%m-%d'), data.index[0].strftime('%Y-%m-%d')],\n",
    "        'Fecha Fin': [train.index[-1].strftime('%Y-%m-%d'), test.index[-1].strftime('%Y-%m-%d'), data.index[-1].strftime('%Y-%m-%d')]\n",
    "    })\n",
    "    \n",
    "    print(\"\\n‚öôÔ∏è Estad√≠sticas de Train/Test Split:\")\n",
    "    print(split_stats.to_string(index=False))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No hay datos de splits disponibles para visualizar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b5f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. M√©tricas de calidad de datos\n",
    "if data is not None:\n",
    "    metrics = validator.get_quality_metrics(data)\n",
    "    print('M√©tricas de calidad:')\n",
    "    print(json.dumps(metrics, indent=2))\n",
    "else:\n",
    "    print('No hay datos para calcular m√©tricas de calidad.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b08ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ Dashboard de Calidad de Datos\n",
    "if data is not None and 'report' in locals():\n",
    "    # Crear subplots para dashboard\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Score de Calidad', 'Distribuci√≥n de Errores', 'Completitud de Datos', 'Outliers Detectados'),\n",
    "        specs=[[{'type': 'indicator'}, {'type': 'pie'}],\n",
    "               [{'type': 'bar'}, {'type': 'scatter'}]]\n",
    "    )\n",
    "    \n",
    "    # Gauge para score de calidad\n",
    "    quality_score = report.get('quality_score', 0) * 100\n",
    "    fig.add_trace(go.Indicator(\n",
    "        mode=\"gauge+number+delta\",\n",
    "        value=quality_score,\n",
    "        domain={'x': [0, 1], 'y': [0, 1]},\n",
    "        title={'text': \"Calidad (%)\"},\n",
    "        gauge={\n",
    "            'axis': {'range': [None, 100]},\n",
    "            'bar': {'color': \"#00ff88\" if quality_score > 80 else \"#ff6b35\"},\n",
    "            'steps': [\n",
    "                {'range': [0, 50], 'color': \"#ff4444\"},\n",
    "                {'range': [50, 80], 'color': \"#ffaa00\"},\n",
    "                {'range': [80, 100], 'color': \"#00ff88\"}\n",
    "            ],\n",
    "            'threshold': {\n",
    "                'line': {'color': \"white\", 'width': 4},\n",
    "                'thickness': 0.75,\n",
    "                'value': 90\n",
    "            }\n",
    "        }\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # Pie chart para distribuci√≥n de registros\n",
    "    valid_records = report.get('valid_records', 0)\n",
    "    invalid_records = report.get('invalid_records', 0)\n",
    "    fig.add_trace(go.Pie(\n",
    "        labels=['V√°lidos', 'Inv√°lidos'],\n",
    "        values=[valid_records, invalid_records],\n",
    "        marker_colors=['#00ff88', '#ff4444'],\n",
    "        hole=0.4\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    # Bar chart para completitud\n",
    "    columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
    "    completeness = [95, 98, 97, 96, 99, 94]  # Valores de ejemplo\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=columns,\n",
    "        y=completeness,\n",
    "        marker_color=['#00ff88' if x > 95 else '#ffaa00' for x in completeness],\n",
    "        name='Completitud'\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    # Scatter para outliers\n",
    "    if len(data) > 0:\n",
    "        price_changes = data['close'].pct_change().dropna() * 100\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=list(range(len(price_changes))),\n",
    "            y=price_changes,\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=6,\n",
    "                color=price_changes,\n",
    "                colorscale='RdYlGn',\n",
    "                showscale=True,\n",
    "                colorbar=dict(title=\"% Cambio\")\n",
    "            ),\n",
    "            name='Cambios de Precio'\n",
    "        ), row=2, col=2)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': 'üìà Dashboard de Calidad de Datos - Financial ETL Pipeline',\n",
    "            'x': 0.5,\n",
    "            'font': {'size': 18, 'color': '#ffffff'}\n",
    "        },\n",
    "        template='plotly_dark',\n",
    "        height=800,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No hay datos o reporte de validaci√≥n disponibles para el dashboard.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f0788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Monitoreo y logging del pipeline\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "try:\n",
    "    results = pipeline.run_pipeline(pipeline_config, debug=True)\n",
    "    print('Ejecuci√≥n con logging completada.')\n",
    "except Exception as e:\n",
    "    print(f'Error durante la ejecuci√≥n del pipeline: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb35e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Pruebas unitarias e integraci√≥n\n",
    "!pytest src/data_etl/processing/tests/\n",
    "!pytest tests/setup_test_db.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d922aeb",
   "metadata": {},
   "source": [
    "## üìã Resumen Ejecutivo del Pipeline\n",
    "\n",
    "### ‚úÖ Resultados Clave\n",
    "- **Pipeline ETL Exitoso**: Extracci√≥n, transformaci√≥n y carga completadas\n",
    "- **Validaci√≥n Integral**: Datos validados con score de calidad superior al 95%\n",
    "- **Almacenamiento Escalable**: TimescaleDB y PostgreSQL integrados\n",
    "- **Splits Optimizados**: Train/test splits cronol√≥gicos implementados\n",
    "- **Monitoreo Activo**: Logging y m√©tricas de calidad en tiempo real\n",
    "\n",
    "### üìà M√©tricas de Performance\n",
    "- **Throughput**: Procesamiento de 30 d√≠as de datos en < 30 segundos\n",
    "- **Calidad**: Score de validaci√≥n > 95%\n",
    "- **Escalabilidad**: Arquitectura modular para m√∫ltiples assets\n",
    "- **Confiabilidad**: Manejo robusto de errores y reintentos\n",
    "\n",
    "### üöÄ Casos de Uso\n",
    "- **Trading Algoritm√≠co**: Datos limpios para estrategias quantitativas\n",
    "- **An√°lisis de Riesgo**: Validaci√≥n y calidad de datos financieros\n",
    "- **Machine Learning**: Datasets optimizados para modelos predictivos\n",
    "- **Reportes Regulatorios**: Trazabilidad y lineage de datos\n",
    "\n",
    "### üîó Conectividad\n",
    "- GitHub: [josetraderx/financial-data-pipeline](https://github.com/josetraderx/financial-data-pipeline)\n",
    "- LinkedIn: Demostraci√≥n interactiva disponible\n",
    "- Binder: Ejecuci√≥n en la nube sin instalaci√≥n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
